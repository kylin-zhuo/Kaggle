{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from cnn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
    "          num_epochs = 10, minibatch_size = 64, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \"\"\"\n",
    "\n",
    "    tf.set_random_seed(1)\n",
    "    seed = 3 \n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = [] \n",
    "\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    W1, W2, W3 = initialize_parameters()\n",
    "    \n",
    "    Z4 = forward_propagation(X, W1, W2, W3)\n",
    "    cost = compute_cost(Z4, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    mincost = float('inf')\n",
    "    ep = 0\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "    \n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            ep += 1\n",
    "            \n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                minibatch_cost += temp_cost / num_minibatches     \n",
    "                \n",
    "            if print_cost == True and epoch % 1 == 0: print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0: costs.append(minibatch_cost)\n",
    "                    \n",
    "            if minibatch_cost < mincost:\n",
    "                ep = 0\n",
    "                mincost = minibatch_cost\n",
    "                save_path = saver.save(sess, CKPT_PATH)\n",
    "                print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "            if ep > 10:\n",
    "                break\n",
    "                \n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        predict_op = tf.argmax(Z4, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.194686\n",
      "Model saved in file: ./cnn/cnn.ckpt\n",
      "Cost after epoch 1: 0.076205\n",
      "Model saved in file: ./cnn/cnn.ckpt\n",
      "Cost after epoch 2: 0.064690\n",
      "Model saved in file: ./cnn/cnn.ckpt\n",
      "Cost after epoch 3: 0.067062\n",
      "Cost after epoch 4: 0.062733\n",
      "Model saved in file: ./cnn/cnn.ckpt\n",
      "Cost after epoch 5: 0.057564\n",
      "Model saved in file: ./cnn/cnn.ckpt\n",
      "Cost after epoch 6: 0.064303\n",
      "Cost after epoch 7: 0.054884\n",
      "Model saved in file: ./cnn/cnn.ckpt\n",
      "Cost after epoch 8: 0.052589\n",
      "Model saved in file: ./cnn/cnn.ckpt\n",
      "Cost after epoch 9: 0.058793\n",
      "Cost after epoch 10: 0.056413\n",
      "Cost after epoch 11: 0.061037\n",
      "Cost after epoch 12: 0.062060\n",
      "Cost after epoch 13: 0.061565\n",
      "Cost after epoch 14: 0.080562\n",
      "Cost after epoch 15: 0.048995\n",
      "Model saved in file: ./cnn/cnn.ckpt\n",
      "Cost after epoch 16: 0.038616\n",
      "Model saved in file: ./cnn/cnn.ckpt\n",
      "Cost after epoch 17: 0.048796\n",
      "Cost after epoch 18: 0.076763\n"
     ]
    }
   ],
   "source": [
    "model(X_train, Y_train, X_test, Y_test, num_epochs = 20, minibatch_size = 64)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
